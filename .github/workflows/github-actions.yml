name: Test Self Hosted Runners
on: push
jobs:
  build:
    runs-on: linux-amd64-cpu8
    container:
      image: rapidsai/devcontainers:23.06-cpp-cuda11.8-mambaforge-ubuntu22.04
      env:
        DEFAULT_CONDA_ENV: legate
    steps:
      - name: Set path
        shell: bash
        run: echo "/opt/conda/bin" >> $GITHUB_PATH
      - name: Checkout legate core
        uses: actions/checkout@v3
        with:
            repository: nv-legate/legate.core
      - name: Install legate core
        run: |
          cd $GITHUB_WORKSPACE/legate.core;
          python scripts/generate-conda-envs.py --python 3.10 --ctk 11.8 --os linux --compilers --openmpi;
          mamba env create -n legate -f environment-test-linux-py3.10-cuda11.8-compilers-openmpi-ucx.yaml;
          mamba install -y -c conda-forge openmpi ucx;
          mamba activate legate;
          ./install.py --network ucx --cuda --arch ampere -j 10;
  job2_gpu:
    runs-on: linux-amd64-gpu-v100-latest-1
    container: # GPU jobs must run in a container
      image: nvidia/cuda:11.8.0-base-ubuntu22.04
      env:
        NVIDIA_VISIBLE_DEVICES: ${{ env.NVIDIA_VISIBLE_DEVICES }} # GPU jobs must set this container env variable
    steps:
      - name: hello
        run: |
          echo "hello"
          nvidia-smi
